{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_answer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filiperobotic/cursoDL/blob/master/codes/aula4/LeNet_answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WppfDvBhkFfd",
        "colab_type": "code",
        "outputId": "cba87e07-15d7-4c2e-e0d1-8b200551609e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "#from pyimagesearch.nn.conv import LeNet\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "U27CsX1OkewH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "\n",
        "def build_LeNet(width, height, depth, classes):\n",
        "  # initialize the model\n",
        "  model = Sequential()\n",
        "  inputShape = (height, width, depth)\n",
        "\n",
        "  # first set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(20, (5, 5), padding=\"same\",\n",
        "    input_shape=inputShape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "  # second set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "  # first (and only) set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(500))\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # return the constructed network architecture\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PU54qS0nD7QS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "def build_MiniVGG(width, height, depth, classes):\n",
        "  # initialize the model\n",
        "  model = Sequential()\n",
        "  inputShape = (height, width, depth)# first CONV => RELU => CONV => RELU => POOL layer set\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "  input_shape=inputShape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # second CONV => RELU => CONV => RELU => POOL layer set\n",
        "  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # first (and only) set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  # return the constructed network architecture\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wu3wYs1lK6P",
        "colab_type": "code",
        "outputId": "5c84e746-e499-477e-9d48-70ff02648033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a minute)\n",
        "print(\"[INFO] accessing MNIST...\")\n",
        "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] accessing MNIST...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "heWhVwACkSti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainData = trainData.reshape((trainData.shape[0], 28, 28, 1))\n",
        "testData = testData.reshape((testData.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkR7Uur6lhXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "trainData = trainData.astype(\"float32\") / 255.0\n",
        "testData = testData.astype(\"float32\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "le = LabelBinarizer()\n",
        "trainLabels = le.fit_transform(trainLabels)\n",
        "testLabels = le.transform(testLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XZ3nqAwlqMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=0.01)\n",
        "#model = build_LeNet(width=28, height=28, depth=1, classes=10)\n",
        "model = build_MiniVGG(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainData, trainLabels,\n",
        "     validation_data=(testData, testLabels), batch_size=128,\n",
        "     epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aARU6R8oltXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testData, batch_size=128)\n",
        "print(classification_report(testLabels.argmax(axis=1),\n",
        "predictions.argmax(axis=1),\n",
        "target_names=[str(x) for x in le.classes_]))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"acc\" ], label=\"train_acc\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKFbHMMzCHIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhkt2ScNGwya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## cifar"
      ]
    },
    {
      "metadata": {
        "id": "qEl80AGNGx47",
        "colab_type": "code",
        "outputId": "a9a64f9f-df1e-41a6-85cf-394bc070d7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# load the training and testing data, then scale it into the\n",
        "# range [0, 1]\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float32\")/255.0\n",
        "testX = testX.astype(\"float32\")/255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "# initialize the label names for the CIFAR-10 dataset\n",
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\",\"frog\", \"horse\", \"ship\", \"truck\" ]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 27s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3uV7HDxkHQhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = SGD(lr=0.01)\n",
        "#model = build_LeNet(width=28, height=28, depth=1, classes=10)\n",
        "model = build_MiniVGG(width=32, height=32, depth=3, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainX, trainY,\n",
        "     validation_data=(testX, testY), batch_size=128,\n",
        "     epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkumElTUH622",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testData, batch_size=128)\n",
        "print(classification_report(testLabels.argmax(axis=1),\n",
        "predictions.argmax(axis=1),\n",
        "target_names=labelNames))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"acc\" ], label=\"train_acc\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKLZ1tAKLDrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}