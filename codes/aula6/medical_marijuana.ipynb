{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_marijuana.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filiperobotic/cursoDL/blob/master/codes/aula6/medical_marijuana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IQFfHPjoqzv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/filiperobotic/cursoDL.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HS8pT6fJq2-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3Aa1AUgxA2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build(width, height, depth, classes, reg):\n",
        "\t\t#TODO\n",
        "    \n",
        "    \n",
        "    \n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb95O8Flxapi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        " \n",
        "# import the necessary packages\n",
        "#from pyimagesearch.simplenet import SimpleNet\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "from imutils import build_montages\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "arg_dataset = \"cursoDL/imagens/datasets/medical-marijuana\"\n",
        "arg_epochs = 100\n",
        "\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(arg_dataset))\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, convert it to grayscale, and resize it to be a\n",
        "\t# fixed 64x64 pixels, ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\timage = cv2.resize(image, (64, 64))\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "# convert the data into a NumPy array, then preprocess it by scaling\n",
        "# all pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "\n",
        "# reshape the data matrix so that it explicity includes a channel\n",
        "# dimension\n",
        "data = data.reshape((data.shape[0], data.shape[1], data.shape[2], 1))\n",
        "\n",
        "# encode the labels (which are currently strings) as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# transform the labels into vectors in the range [0, classes],\n",
        "# generating a vector for each label, where the index of the label\n",
        "# is set to '1' and all other entries are set to '0' -- this process\n",
        "# is called \"one-hot encoding\"\n",
        "labels = np_utils.to_categorical(labels, 2)\n",
        "\n",
        "# partition the data into training and testing splits using 60% of\n",
        "# the data for training and the remaining 40% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.40, stratify=labels, random_state=42)\n",
        "\n",
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "\n",
        "#TODO: compile model\n",
        "\n",
        "\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network for {} epochs...\".format(\n",
        "\targ_epochs))\n",
        "#TODO: train model\n",
        "H = \n",
        "\n",
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=le.classes_))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fsIVAw5yMXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = arg_epochs\n",
        "\n",
        "plt.figure()\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "#plt.savefig(args[\"plot\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xpazltmqzWGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# randomly select a few testing images and then initialize the output\n",
        "# set of images\n",
        "idxs = np.arange(0, testY.shape[0])\n",
        "idxs = np.random.choice(idxs, size=(25,), replace=False)\n",
        "images = []\n",
        "\n",
        "# loop over the testing indexes\n",
        "for i in idxs:\n",
        "\t# grab the current testing image and classify it\n",
        "\timage = np.expand_dims(testX[i], axis=0)\n",
        "\tpreds = model.predict(image)\n",
        "\tj = preds.argmax(axis=1)[0]\n",
        "\tlabel = le.classes_[j]\n",
        "\n",
        "\t# rescale the image into the range [0, 255] and then resize it so\n",
        "\t# we can more easily visualize it\n",
        "\toutput = (image[0] * 255).astype(\"uint8\")\n",
        "\toutput = np.dstack([output] * 3)\n",
        "\toutput = cv2.resize(output, (128, 128))\n",
        "\n",
        "\t# draw the class label on the output image and add it to the set\n",
        "\t# of output images\n",
        "\tcv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "\t\t(0, 0, 255), 2)\n",
        "\timages.append(output)\n",
        "\n",
        "# create a montage using 128x128 \"tiles\" with 5 rows and 5 columns\n",
        "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
        "\n",
        "# show the output montage\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.add_subplot(1,1,1, xticks=[], yticks=[])\n",
        "ax.imshow(montage)\n",
        "#cv2.imshow(\"Output\", montage)\n",
        "#cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_TpQ-Pz0Umv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}